{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tldextract\n",
    "!pip install xgboost\n",
    "!pip install pandas numpy beautifulsoup4 textblob scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scipy\n",
    "!pip install nltk\n",
    "!pip install wordcloud\n",
    "!pip install scipy\n",
    "!pip install nltk\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import urllib.parse\n",
    "from collections import Counter\n",
    "import tldextract\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Information About the Dataset\n",
      "Dataset shape: (200609, 2521)\n",
      "Class distribution:\n",
      "label\n",
      "0.0    107534\n",
      "1.0     93075\n",
      "Name: count, dtype: int64\n",
      "Custom features: 2521\n",
      "TF-IDF features: 0\n",
      "\n",
      "============================================================\n",
      "MODEL SELECTION USING 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "Testing models with default parameters...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Testing Random Forest...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f_classif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 140\u001b[39m\n\u001b[32m    138\u001b[39m X, y = load_and_prepare_data()\n\u001b[32m    139\u001b[39m custom_features, tfidf_features = identify_feature_types(X)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m best_model_name, best_model, model_scores = \u001b[43mmodel_selection_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_features\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m print_results(best_model_name, model_scores)\n\u001b[32m    145\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mmodel_selection_pipeline\u001b[39m\u001b[34m(X, y, custom_features, tfidf_features)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m#this i\u001b[39;00m\n\u001b[32m     91\u001b[39m pipeline = Pipeline([\n\u001b[32m     92\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocess\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mselect\u001b[39m\u001b[33m'\u001b[39m, SelectKBest(\u001b[43mf_classif\u001b[49m, k=\u001b[32m1000\u001b[39m)),\n\u001b[32m     94\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m'\u001b[39m, model)\n\u001b[32m     95\u001b[39m ])\n\u001b[32m     97\u001b[39m scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\u001b[33m'\u001b[39m\u001b[33mf1_weighted\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m     98\u001b[39m mean_score = scores.mean()\n",
      "\u001b[31mNameError\u001b[39m: name 'f_classif' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    print(\"Basic Information About the Dataset\")\n",
    "    df = pd.read_csv('final_phishing_dataset.csv')\n",
    "    \n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    \n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Class distribution:\\n{y.value_counts()}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#i need to seperate the features into custom features and tf-idf features since i need to standardize the custom features and use tf-idf for the rest\n",
    "def identify_feature_types(X):\n",
    "    # separate custom features from tf-idf features\n",
    "    total_features = X.shape[1]\n",
    "    tfidf_count = 5000\n",
    "    \n",
    "    if total_features > tfidf_count:\n",
    "        custom_features = list(X.columns[:-tfidf_count])\n",
    "        tfidf_features = list(X.columns[-tfidf_count:])\n",
    "    else:\n",
    "        custom_features = list(X.columns)\n",
    "        tfidf_features = []\n",
    "    \n",
    "    print(f\"Custom features: {len(custom_features)}\")\n",
    "    print(f\"TF-IDF features: {len(tfidf_features)}\")\n",
    "    \n",
    "    return custom_features, tfidf_features\n",
    "\n",
    "#\n",
    "def create_preprocessing_pipeline(custom_features, tfidf_features):\n",
    "    # create models for different feature types\n",
    "    transformers = []\n",
    "    \n",
    "    #WE NEED TO STANDARDIZE THE CUSTOM FEATURES BECAUSE THEY ARE NOT ON THE SAME SCALE AS THE TF-IDF FEATURES\n",
    "    if custom_features:\n",
    "        transformers.append(('custom', StandardScaler(), custom_features))\n",
    "    \n",
    "    #leave the tfidf features as they are\n",
    "    if tfidf_features:\n",
    "        transformers.append(('tfidf', 'passthrough', tfidf_features))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=transformers,remainder='drop')\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def model_selection_pipeline(X, y, custom_features, tfidf_features):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL SELECTION USING 5-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # define models to test with default parameters\n",
    "    models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "    \n",
    "    preprocessor = create_preprocessing_pipeline(custom_features, tfidf_features)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    model_scores = {}\n",
    "    best_model_name = None\n",
    "    best_score = 0\n",
    "    \n",
    "    print(\"\\nTesting models with default parameters...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTesting {name}...\")\n",
    "        \n",
    "        #this i\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocess', preprocessor),\n",
    "            ('select', SelectKBest(f_classif, k=1000)),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        \n",
    "        model_scores[name] = {\n",
    "            'mean_score': mean_score,\n",
    "            'std_score': std_score,\n",
    "            'scores': scores,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        print(f\"Mean F1 Score: {mean_score})\")\n",
    "        print(f\"Individual cross validation scores: {scores}\")\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_model_name = name\n",
    "    \n",
    "    return best_model_name, models[best_model_name], model_scores\n",
    "\n",
    "def print_results(best_model_name, model_scores):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MODEL SELECTION RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # sort models by performance\n",
    "    sorted_models = sorted(model_scores.items(), key=lambda x: x[1]['mean_score'], reverse=True)\n",
    "    \n",
    "    print(\"\\nModel Rankings (by F1 Score):\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (name, scores) in enumerate(sorted_models, 1):\n",
    "        print(f\"{i}. {name}: {scores['mean_score']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"BEST MODEL: {best_model_name}\")\n",
    "    print(f\"Best F1 Score: {model_scores[best_model_name]['mean_score']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "#MAIN SECTION WHERE EVERYTHING WILL BE EXECUTED\n",
    "\n",
    "X, y = load_and_prepare_data()\n",
    "custom_features, tfidf_features = identify_feature_types(X)\n",
    "best_model_name, best_model, model_scores = model_selection_pipeline(\n",
    "    X, y, custom_features, tfidf_features\n",
    ")\n",
    "print_results(best_model_name, model_scores)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Model Selection Completed\")\n",
    "print(f\"{'='*60}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352eea11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531bfd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
